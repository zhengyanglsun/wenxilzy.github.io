<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no"><title>数据挖掘与大数据分析复习 | Komorebi</title><meta name="keywords" content="数据挖掘与大数据分析,复习"><meta name="author" content="Komorebi,2039222749@qq.com"><meta name="copyright" content="Komorebi"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="题型  选择题——单选、多选 大题——2道计算题 大部分是简答题 最后一题是综合题    决策树的流程 聚类有哪些类型 数据挖掘的任务有哪些~ 关联规则挖掘 分类&#x2F;预测 与 回归 聚类分析 孤立点检测   第一章 数据挖掘与大数据简介  复习提纲  基本概念  什么是大数据 什么是数据挖掘   大数据的4V特征 数据挖掘的主要任务 KDD过程（数据挖掘是核心） DM（数据挖掘）挑战 数据挖掘和多个">
<meta property="og:type" content="article">
<meta property="og:title" content="数据挖掘与大数据分析复习">
<meta property="og:url" content="https://wenxilzy.github.io/2022/05/27/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98%E4%B8%8E%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E5%A4%8D%E4%B9%A0/index.html">
<meta property="og:site_name" content="Komorebi">
<meta property="og:description" content="题型  选择题——单选、多选 大题——2道计算题 大部分是简答题 最后一题是综合题    决策树的流程 聚类有哪些类型 数据挖掘的任务有哪些~ 关联规则挖掘 分类&#x2F;预测 与 回归 聚类分析 孤立点检测   第一章 数据挖掘与大数据简介  复习提纲  基本概念  什么是大数据 什么是数据挖掘   大数据的4V特征 数据挖掘的主要任务 KDD过程（数据挖掘是核心） DM（数据挖掘）挑战 数据挖掘和多个">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://cdn.acwing.com/media/article/image/2022/05/16/99310_ddc885a5d4-00117.png">
<meta property="article:published_time" content="2022-05-27T13:50:30.000Z">
<meta property="article:modified_time" content="2022-06-05T13:58:36.176Z">
<meta property="article:author" content="Komorebi">
<meta property="article:tag" content="数据挖掘与大数据分析">
<meta property="article:tag" content="复习">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://cdn.acwing.com/media/article/image/2022/05/16/99310_ddc885a5d4-00117.png"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="https://wenxilzy.github.io/2022/05/27/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98%E4%B8%8E%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E5%A4%8D%E4%B9%A0/"><link rel="preconnect" href="//fastly.jsdelivr.net"/><link rel="preconnect" href="//fonts.googleapis.com" crossorigin=""/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://fastly.jsdelivr.net/npm/@fortawesome/fontawesome-free@6/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://fastly.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Titillium+Web&amp;display=swap" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"search.xml","languages":{"hits_empty":"找不到您查询的内容：${query}"}},
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '天',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'mediumZoom',
  Snackbar: undefined,
  source: {
    justifiedGallery: {
      js: 'https://fastly.jsdelivr.net/npm/flickr-justified-gallery@2/dist/fjGallery.min.js',
      css: 'https://fastly.jsdelivr.net/npm/flickr-justified-gallery@2/dist/fjGallery.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: '数据挖掘与大数据分析复习',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2022-06-05 21:58:36'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><link rel="stylesheet" href="/static/css/custom.css"><meta name="generator" content="Hexo 6.1.0"></head><body><div id="loading-box"><div class="loading-left-bg"></div><div class="loading-right-bg"></div><div class="spinner-box"><div class="configure-border-1"><div class="configure-core"></div></div><div class="configure-border-2"><div class="configure-core"></div></div><div class="loading-word">加载中...</div></div></div><div id="web_bg"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="https://cdn.acwing.com/media/article/image/2022/04/28/99310_dfcf84d4c6-touxiang.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data is-center"><div class="data-item"><a href="/archives/"><div class="headline">文章</div><div class="length-num">55</div></a></div><div class="data-item"><a href="/tags/"><div class="headline">标签</div><div class="length-num">18</div></a></div><div class="data-item"><a href="/categories/"><div class="headline">分类</div><div class="length-num">5</div></a></div></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 归档</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 链接</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('https://cdn.acwing.com/media/article/image/2022/05/16/99310_ddc885a5d4-00117.png')"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">Komorebi</a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 归档</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 链接</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">数据挖掘与大数据分析复习</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2022-05-27T13:50:30.000Z" title="发表于 2022-05-27 21:50:30">2022-05-27</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2022-06-05T13:58:36.176Z" title="更新于 2022-06-05 21:58:36">2022-06-05</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/">课程笔记</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">字数总计:</span><span class="word-count">7.4k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>22分钟</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="数据挖掘与大数据分析复习"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h2 id="题型">题型</h2>
<ul>
<li>选择题——单选、多选</li>
<li>大题——2道计算题 大部分是简答题 最后一题是综合题</li>
</ul>
<blockquote>
<ul>
<li>决策树的流程</li>
<li>聚类有哪些类型</li>
<li>数据挖掘的任务有哪些~</li>
<li>关联规则挖掘</li>
<li>分类/预测 与 回归</li>
<li>聚类分析</li>
<li>孤立点检测</li>
</ul>
</blockquote>
<h2 id="第一章-数据挖掘与大数据简介">第一章 数据挖掘与大数据简介</h2>
<p><img src="https://img-blog.csdnimg.cn/20210604113812714.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQ1NzA0OTQy,size_16,color_FFFFFF,t_70" alt=""></p>
<h3 id="复习提纲">复习提纲</h3>
<ol>
<li>基本概念
<ul>
<li>什么是大数据</li>
<li>什么是数据挖掘</li>
</ul>
</li>
<li>大数据的4V特征</li>
<li>数据挖掘的主要任务</li>
<li>KDD过程（数据挖掘是核心）</li>
<li>DM（数据挖掘）挑战</li>
<li>数据挖掘和多个学科的融合</li>
</ol>
<h3 id="基本概念">基本概念</h3>
<h4 id="什么是大数据">什么是大数据</h4>
<p>大数据是一个流行词，或称流行语，用来描述大量的结构化和非结构化数据，这些数据如此之大，<br>
很难使用传统的数据库和软件技术进行处理<br>
无法在<strong>一定时间内用常规软件工具</strong>对其内容进行<strong>抓取，管理，处理</strong>的数据集合<br>
是要更新处理模式才能具有更强的决策力，洞察发现力，流程优化能力来适应海量，高增长率，多样化的信息资产</p>
<h4 id="什么是数据挖掘">什么是数据挖掘</h4>
<p>从<strong>大量</strong>数据中挖掘那些<strong>令人感兴趣的，有用的，隐含的，先前未知的，可能有用的模式或者知识</strong></p>
<p>关键是从“大量的数据中挖掘令人感兴趣的模式或知识”<br>
<strong>注意</strong>：并非所有数据分析都是“数据挖掘”</p>
<ul>
<li>查询处理</li>
<li>专家系统或者是数学计算/统计程序</li>
</ul>
<h4 id="大数据的4V特征">大数据的4V特征</h4>
<ul>
<li>规模性</li>
<li>多样性</li>
<li>高速性</li>
<li>价值性</li>
</ul>
<h3 id="数据挖掘主要任务">数据挖掘主要任务</h3>
<ol>
<li><strong>关联规则分析</strong> 发掘数据之间的关联规则，如挖掘空气质量和气象条件之间的关系</li>
<li><strong>聚类分析</strong> 将数据归为不同的类，形成新的类别进行分析，最大化<strong>类内相似性</strong>和最小化<strong>类间相似性</strong></li>
<li><strong>分析 回归 预测</strong> 找出描述和区分数据类或者概念的模型 让该模型可以预测未知的对象类标签</li>
<li><strong>离群点分析</strong> 分析孤立而原本会被当作噪音丢弃的数据 在欺骗检测中通过孤立点分析得到的结论</li>
</ol>
<blockquote>
<p>这些内容在之后的章节都会讲到</p>
</blockquote>
<h3 id="（重点）KDD过程（知识发现过程）">（重点）KDD过程（知识发现过程）</h3>
<p>KDD：从数据中获取知识</p>
<ol>
<li>数据清理：消除噪声和删除不一致的数据</li>
<li>数据集成： 多种数据源可以组合在一起</li>
<li>数据选择：从数据库中提取与分析任务相关的数据</li>
<li>数据变化：把数据变换和统一成适合挖掘的形式</li>
<li><strong>数据挖掘</strong>：核心步骤，<strong>使用智能方法提取数据模式</strong></li>
</ol>
<blockquote>
<p>知识发现的核心是数据挖掘！</p>
</blockquote>
<ol start="6">
<li>模式评估：根据兴趣度度量，识别代表知识的真正有趣的模式</li>
<li>知识表示：使用可视化和知识表示技术，向用户提供挖掘的知识</li>
</ol>
<blockquote>
<p>注意数据挖掘是核心</p>
</blockquote>
<h3 id="数据挖掘挑战">数据挖掘挑战</h3>
<p>数据<strong>容量</strong> <code>Scale of Data</code>——VOLUMN<br>
数据的实时性 <code>Data Stream</code> ——VELOCITY<br>
数据的多样性<code>Different format of data different sources</code>——VARIETY<br>
数据的不确定性 <code> Uncertainty, missing value</code></p>
<h3 id="数据挖掘与多个学科融合">数据挖掘与多个学科融合</h3>
<ul>
<li>机器学习，数据库系统，信息检索</li>
<li>统计学，物理学，其他学科</li>
</ul>
<h2 id="第二章-认识数据和数据预处理">第二章 认识数据和数据预处理</h2>
<h3 id="复习提纲-2">复习提纲</h3>
<ol>
<li>属性类型</li>
<li>数据的统计描述</li>
</ol>
<ul>
<li>中心性
<ul>
<li>均值</li>
<li>众数</li>
<li>中位数</li>
<li>中列数</li>
</ul>
</li>
<li>散度
<ul>
<li>极差</li>
<li>最小</li>
<li>最大</li>
<li>四分位</li>
<li>百分位</li>
<li>方差</li>
</ul>
</li>
</ul>
<ol start="3">
<li>相似性度量</li>
</ol>
<ul>
<li>标称<code>d(i,j)=#不同/# 总</code></li>
<li>数值
<ul>
<li>欧式</li>
<li>曼哈顿</li>
</ul>
</li>
<li>数据标准化
<ul>
<li>最大最小法</li>
<li>Z-Score</li>
</ul>
</li>
<li>其他相似性
<ul>
<li>余弦相似性</li>
<li>马氏距离</li>
<li>相关散度</li>
<li>KL散度</li>
</ul>
</li>
<li>数据预处理<br>
清理$\to$集成$\to$规约$\to$变换$\to$离散化</li>
<li>清理：缺值，噪声</li>
<li>集成：相关分析，卡方分析</li>
<li>规约：采用PCA小波分析，特征筛选（信息增益）</li>
<li>变换：最大最小法，E-score，数据离散化</li>
</ul>
<ol start="4">
<li>数据类型</li>
</ol>
<h3 id="属性类型">属性类型</h3>
<p><strong>分类型</strong></p>
<ul>
<li>标称型-<strong>特殊（二元）</strong></li>
</ul>
<blockquote>
<p>标称型目标变量的结果<strong>只在有限目标集中取值</strong>，比如真与假（标称型目标变量主要用于<strong>分类</strong>）</p>
<ul>
<li>例：ID号，眼球颜色，邮政编码</li>
<li>特殊：二元</li>
</ul>
</blockquote>
<ul>
<li>序数型
<ul>
<li>例：军阶，GPA，用{tall,medium,short}表示身高</li>
</ul>
</li>
</ul>
<p><strong>数值型</strong></p>
<blockquote>
<p>数值型目标变量则可以<strong>从无限的数值集合中取值</strong>，如0.555，666.666等（数值型目标变量主要用于<strong>回归分析</strong>）</p>
</blockquote>
<ul>
<li>区间
<ul>
<li>例如：日历，摄氏或华氏温度</li>
</ul>
</li>
<li>比率
<ul>
<li>例如：开式温度，长度，计数</li>
</ul>
</li>
<li><strong>标称属性</strong>的值是一些符号和事物的名称（比如头发的颜色）</li>
</ul>
<blockquote>
<p>标称：意味着“与名称有关”</p>
</blockquote>
<p><strong>离散和连续属性</strong><br>
<strong>二元属性</strong>是标称的一种 1代表有 0代表没有<br>
如果是对称的说明无权重（例如男女性别）<br>
如果是非对称的说明有权重（例如检测结果为阴性/阳性） 一个值比另一个值重要，重要的通常较少出现，通常用1表示</p>
<p>数值属性：区间，比率</p>
<h3 id="数据类型">数据类型</h3>
<ul>
<li>记录数据
<ul>
<li>数据矩阵</li>
<li>文档数据</li>
<li>购物篮数据</li>
</ul>
</li>
<li>图数据
<ul>
<li>万维网</li>
<li>分子结构</li>
</ul>
</li>
<li>有序数据
<ul>
<li>时序数据</li>
<li>序列数据</li>
<li>基因序列数据</li>
<li>空间数据</li>
</ul>
</li>
</ul>
<h3 id="（重点）【选填题】数据的描述性统计">（重点）【选填题】数据的描述性统计</h3>
<p><strong>中心趋势度量：均值，众数，中位数，中列数</strong>——（中心性描述）<br>
<strong>数据的散步：极差，四分位数，四分位数极差，五数概括，盒图</strong>——（散布描述）<br>
<strong>可视化</strong></p>
<ul>
<li>分位数图</li>
<li>分位数-分位数图</li>
<li>直方图</li>
</ul>
<h4 id="中心趋势度量">中心趋势度量</h4>
<p><strong>均值</strong><br>
均值=总和/个数</p>
<p>加权平均：考虑权重的均值</p>
<p><strong>中列数</strong><br>
数据集的最大和最小值的平均值</p>
<p><strong>中位数（median）</strong><br>
有序数据值的中间值</p>
<p>大数据：近似值估计（线性插值法）</p>
<p><strong>众数（mode）</strong><br>
在集合中出现最频繁的值。（一个数据集中可能有多个众数）</p>
<p>对于非对称的单峰数据，有以下经验关系</p>
<p><code>mean-mode ~ 3 * (mean-median)</code>即为<code>均值-众数近似等于3*（均值-中位数）</code></p>
<blockquote>
<p>选填可能会考！</p>
</blockquote>
<h4 id="数据的散布">数据的散布</h4>
<ul>
<li>方差</li>
<li>标准差</li>
<li>极差</li>
</ul>
<p><strong>max-min</strong></p>
<ul>
<li>四分位数（quantile）</li>
<li>四分位数极差（距离）<br>
<code>IQR=Q3-Q1</code></li>
<li>五数概括</li>
</ul>
<blockquote>
<p>[min, Q1,median,Q3,max]</p>
</blockquote>
<h3 id="（重点）【上机实习】-数据的相似度度量">（重点）【上机实习】 数据的相似度度量</h3>
<h4 id="标称属性数据">标称属性数据</h4>
<p>标称变量是二元变量的拓展，它可以取多于两种状态</p>
<p>相异性度量方法中，不匹配率</p>
<p>计算方法为 $d(i,j)=\frac{p-m}{p}$</p>
<blockquote>
<p>m是状态取值匹配的变量数目 p是变量总数</p>
</blockquote>
<h4 id="二元变量属性数据">二元变量属性数据</h4>
<p>首先获取列联表<br>
<img src="https://cdn.acwing.com/media/article/image/2022/05/30/99310_de3d687adf-1.png" alt="1.png"></p>
<p>对称的二元变量的相异度计算</p>
<blockquote>
<p>对于对称属性，r+s是一个1一个0的总数和，q是两个1</p>
</blockquote>
<p>$$d(i,j)=\frac{r+s}{q+r+s+t}$$</p>
<p>如果是非对称则t被忽略<br>
$$d(i,j)=\frac{r+s}{q+r+s}=1-\frac{q}{q+r+s}=1-Jaccard(i,j)$$</p>
<p>不对称的二元变量的相异度计算</p>
<blockquote>
<p>二元变量的两个状态的输出不是同样重要</p>
</blockquote>
<h4 id="序数型变量数据">序数型变量数据</h4>
<p><img src="https://cdn.acwing.com/media/article/image/2022/05/30/99310_730900c2df-2.png" alt="2.png"></p>
<h4 id="数值属性数据">数值属性数据</h4>
<p>使用<strong>距离</strong>来度量两个数据对象之间的<strong>相似性/相异性</strong></p>
<ul>
<li>闵可夫斯基(Minkowski) 距离</li>
<li>曼哈顿距离</li>
</ul>
<blockquote>
<p>一维 绝对值之和</p>
</blockquote>
<ul>
<li>欧式距离</li>
</ul>
<blockquote>
<p>二维开根号</p>
</blockquote>
<h4 id="数据标准化">数据标准化</h4>
<p><strong>使用平均绝对偏差比使用标准差更具有鲁棒性</strong></p>
<h4 id="混合型数据">混合型数据</h4>
<p><strong>基本思想</strong>：将不同类型的变量组合在<strong>单个相异度矩阵中</strong>，把所有变量转换到共同的值域区间[0.0,1.0]上</p>
<h4 id="相似性度量">相似性度量</h4>
<ul>
<li>余弦相似性</li>
<li>马氏距离</li>
<li>相关散度</li>
<li>KL散度</li>
</ul>
<h3 id="（重点）数据预处理">（重点）数据预处理</h3>
<h4 id="为什么要挖掘？">为什么要挖掘？</h4>
<p>现实世界的数据是“肮脏的”</p>
<ul>
<li>不完整的：有些感兴趣的属性缺少属性值，或仅包含聚集数据</li>
<li>含噪声的：包含错误或者“孤立点”</li>
<li>不一致的：在编码或者命名上存在差异</li>
</ul>
<p>没有高质量的数据，就没有高质量的挖掘结果</p>
<h4 id="数据预处理的主要任务">数据预处理的主要任务</h4>
<h5 id="（重点）-数据清理-（数据的填充方式重点）">（重点） 数据清理 （数据的填充方式重点）</h5>
<p>【重点】填充方法</p>
<ul>
<li>忽略元组</li>
<li>人工填充缺省值：工作量大，可行性低</li>
<li>使用一个全局变量填充空缺值：比如使用unknown或-∞替换</li>
<li>使用属性的平均值填充空缺值</li>
<li>使用与给定元组属同一类的所有样本的均值</li>
<li>使用最可能的值填充空缺值：使用像Bayesian公式或判定树这样的预测的方法</li>
</ul>
<blockquote>
<p>空缺值 噪声数据 删除孤立点 解决不一致性</p>
</blockquote>
<p>用均值或者用临近数</p>
<p>噪声使用过滤的方法（聚类，回归，分箱）</p>
<p><img src="https://cdn.acwing.com/media/article/image/2022/05/30/99310_a40d3865df-3.png" alt="3.png"></p>
<h5 id="数据集成">数据集成</h5>
<p>将多个数据源的数据整合到一个一致的存储中</p>
<p>集成多个数据库时，经常会出现冗余数据</p>
<p><strong>冗余分析</strong>：</p>
<ul>
<li>数字型 相关分析 皮尔逊相关系数</li>
<li>标称数据 卡方检验<br>
<img src="https://cdn.acwing.com/media/article/image/2022/05/30/99310_6cac7c94df-4.png" alt="4.png"></li>
</ul>
<h5 id="数据规约">数据规约</h5>
<p>得到数据集的压缩表示，但可以得到相同或相近的结果</p>
<p>分为</p>
<ol>
<li>维度规约：小波分析，<strong>PCA，特征筛选</strong></li>
<li>数量规约：回归，<strong>聚类，采样</strong>，数据立方体聚集</li>
<li>数据压缩（非重点）：使用变换</li>
</ol>
<p><strong>维度规约</strong>：PCA，小波分析，<strong>特征筛选</strong><br>
**PCA基本思想：**找到一个投影，其能表示数据的最大变化</p>
<blockquote>
<p>特征筛选<br>
目的：通过删除不相干的属性或维减少数据量<br>
挑战：枚举所有几乎不可能<br>
策略：启发式方法</p>
</blockquote>
<ul>
<li>逐步向前选择法</li>
<li>逐步向后删除法</li>
<li>向前选择和向后删除相结合</li>
</ul>
<p>利用信息增益，信息熵等（信息增益越大越好）</p>
<blockquote>
<blockquote>
<p>信息熵：刻画信息的混乱程度</p>
</blockquote>
</blockquote>
<p><img src="https://cdn.acwing.com/media/article/image/2022/05/30/99310_3ac0b253df-1.png" alt="1.png"><br>
<img src="https://cdn.acwing.com/media/article/image/2022/05/30/99310_f61ae973df-2.png" alt="2.png"><br>
<img src="https://cdn.acwing.com/media/article/image/2022/05/30/99310_2f00c283df-3.png" alt="3.png"></p>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/xwd18280820053/article/details/70739368">信息熵的介绍</a></p>
<p><strong>数量规约</strong>：回归，聚类，采样</p>
<h5 id="数据变化">数据变化</h5>
<blockquote>
<p>规范化和聚集<br>
把数据变换和统一成适合挖掘的形式</p>
</blockquote>
<ul>
<li>最大最小规范化</li>
<li>Z-score规范化</li>
</ul>
<h5 id="数据离散化">数据离散化</h5>
<p>将连续数据进行离散处理</p>
<p>离散化（连续数据）<br>
概念分层（标称数据）</p>
<h2 id="第三章-关联规则挖掘">第三章 关联规则挖掘</h2>
<h3 id="复习提纲-3">复习提纲</h3>
<p>定义</p>
<ul>
<li>关联规则挖掘</li>
<li>频繁模式</li>
<li>项集</li>
<li>支持度/计数</li>
<li>置信度</li>
</ul>
<p><code>Apriori</code>算法</p>
<ul>
<li>剪枝基本思想</li>
<li><code>Apriori</code>流程，计算</li>
<li>存在挑战及改进</li>
</ul>
<p>FP-Growth算法</p>
<ul>
<li>如何构造FP树</li>
<li>如何挖掘</li>
</ul>
<p>评估方法</p>
<ul>
<li>支持度</li>
<li>置信度</li>
<li>兴趣因子</li>
</ul>
<h3 id="定义以及一些概念">定义以及一些概念</h3>
<p>关联规则的挖掘：在事务，关系数据库中的项集和对象中发现<strong>频繁模式，关联规则，相关性</strong>或者<strong>因果结构</strong></p>
<p>频繁模式：数据库中频繁出现的项集</p>
<p>支持度 support</p>
<p>置信度 confidence</p>
<p>这两个标准来衡量事物关联规则的强度</p>
<ul>
<li>支持度support$X\to Y$：确定项集的频繁程度</li>
</ul>
<p>包含项集的事务数与总事务数的比值</p>
<ul>
<li>置信度</li>
<li>项集</li>
<li>频繁项集</li>
<li>置信度计算公式</li>
</ul>
<h3 id="Apriori算法">Apriori算法</h3>
<p>通过对数据的多次扫描来计算项集的支持度，发现所有频繁项集从而生成关联规则</p>
<p>剪枝的基本思想</p>
<p><strong>性质1：如果一个项集是频繁的，则它的所有子集一定也是频繁的</strong></p>
<p><strong>性质2：相反，如果一个项集是非频繁的，则它的所有超集也一定是非频繁的</strong></p>
<p><strong>提高Apriori算法的方法</strong></p>
<ul>
<li>Hash-based itemset counting（散列项集计数），压缩候选k项集</li>
<li>Transaction reduction（事务压缩），删除不可能对寻找频繁项集有用的事务</li>
<li>Partitioning（划分），分而治之</li>
<li>Sampling（采样），选取原数据库的一个样本, 使用Apriori 算法在样本中挖掘频繁模式</li>
</ul>
<h3 id="FP-growth算法">FP-growth算法</h3>
<p>优点：<strong>快</strong><br>
该算法不同于Apriori算法的“产生-测试”范型。而是使用一种称为FP树的紧凑数据结构组织数据，并<strong>直接从该结构中提取频繁项集</strong></p>
<p><strong>基本思想</strong><br>
首先：将<strong>代表频繁项集的数据库</strong>压缩到FP树上<br>
其次：将FP树划分为一组条件数据库（每个数据关联一个频繁项或“模式段”），挖掘每个条件数据库获取频繁项集<br>
<strong>如何构造FP树</strong></p>
<ol>
<li>支持度排序</li>
<li>构建FP树</li>
</ol>
<h3 id="支持度，置信度及兴趣因子">支持度，置信度及兴趣因子</h3>
<h2 id="第四章-分类-回归">第四章 分类/回归</h2>
<h3 id="复习提纲-4">复习提纲</h3>
<p>基本概念</p>
<ul>
<li>监督/无监督</li>
<li>生成/判别</li>
<li>分类 VS 回归</li>
</ul>
<p>分类算法</p>
<ul>
<li>（重点）决策树
<ul>
<li>建构过程</li>
<li>属性选择基本准则</li>
<li>信息增益率</li>
<li>基尼指数</li>
</ul>
</li>
<li>（重点）过拟合问题
<ul>
<li>如何避免</li>
<li>决策树中</li>
</ul>
</li>
<li>（重点）KNN
<ul>
<li>基本思想</li>
<li>优缺点</li>
</ul>
</li>
<li>Naive Bayes 朴素贝叶斯
<ul>
<li>贝叶斯理论（优缺点）</li>
</ul>
</li>
<li>（重点）SVM支持向量机
<ul>
<li>支持向量/小样本/泛化能力</li>
<li>基本思想</li>
<li>非线性函数： 核函数</li>
</ul>
</li>
<li>人工神经网络</li>
</ul>
<p>集成学习</p>
<ul>
<li>学习准则
<ul>
<li>准确性</li>
<li>多样性</li>
</ul>
</li>
<li>集成策略
<ul>
<li>RF</li>
<li>Ada Boost</li>
<li>Stacking</li>
</ul>
</li>
</ul>
<p>评估</p>
<ul>
<li>准确度</li>
<li>轻度</li>
<li>吕四率</li>
<li>F1</li>
<li>类不平衡：灵敏性，特效性</li>
</ul>
<h3 id="基本概念-2">基本概念</h3>
<h4 id="监督学习-VS-无监督学习">监督学习 VS 无监督学习</h4>
<p>监督学习</p>
<p>分类，预测等</p>
<blockquote>
<p>“告诉机器怎么学”</p>
</blockquote>
<p>无监督学习</p>
<p>关联规则挖掘，聚类分析都是无监督学习</p>
<blockquote>
<p>“不告诉机器怎么学”</p>
</blockquote>
<h4 id="（重要）-模型分类">（重要） 模型分类</h4>
<h5 id="生成模型">生成模型</h5>
<p>希望从数据中<strong>学习/还原出原始的真实数据生成模型</strong></p>
<blockquote>
<p>朴素贝叶斯，隐马尔可夫模型</p>
</blockquote>
<h5 id="判别模型">判别模型</h5>
<p>从数据中<strong>学习到</strong>不同类概念的<strong>区别从而进行分类</strong></p>
<blockquote>
<p>KNN SVM ANN 决策树</p>
</blockquote>
<h5 id="二者的区别">二者的区别</h5>
<p>生成模型</p>
<ul>
<li>容量大 生成模型容易接近真实模型</li>
<li>能够处理具有<strong>隐含变量</strong>的情景</li>
</ul>
<p>判别模型</p>
<ul>
<li>速度快</li>
<li>准确率高</li>
</ul>
<p>分类和回归</p>
<p>分类：根据训练数据集和类标号属性，构建模型来分类现有数据，并用来分类新数据</p>
<p>预测：建立连续函数值模型，预测未来的情况比如预测空缺值</p>
<h3 id="决策树（DT）">决策树（DT）</h3>
<h4 id="（重点）-决策树的优缺点">（重点） 决策树的优缺点</h4>
<p>优点</p>
<ul>
<li>容易转换成分类规则</li>
<li>计算量相对较小，所以速度较快</li>
<li>准确性高（挖掘出来的分类规则准确性高 便于理解）</li>
</ul>
<p>缺点</p>
<ul>
<li>容易过拟合</li>
<li>忽略了属性之间的相关性</li>
</ul>
<h4 id="（重点）-构建决策树的方法">（重点） 构建决策树的方法</h4>
<p>构造方式</p>
<h4 id="（重点）-属性选择基本准则">（重点） 属性选择基本准则</h4>
<p>具有最好度量得分的属性（对分类数据类别越“纯”）选定为分裂属性</p>
<p>三种度量：信息增益，信息增益率，Gini指标</p>
<h5 id="（重点）-信息增益（ID3）">（重点） 信息增益（ID3）</h5>
<p>信息增益：原来的信息与分裂后的信息之差，说明我们通过划分得到了多少信息</p>
<h5 id="（重点）-信息增益率（C4-5）">（重点） 信息增益率（C4.5）</h5>
<p>信息增益倾向于有大量不同取值的属性，但每个划分只有一个类的时候 info=0</p>
<p>C4.5（ID3后继）使用增益率来克服这一问题（规范化信息增益）</p>
<p>公式为信息增益/根据当前的那个类利用信息熵计算出来的值，越大越好</p>
<h5 id="Gini指数（CART）">Gini指数（CART）</h5>
<p>Gini指数度量数据元组的不纯度，越小越好</p>
<p>如果是三个属性，要进行二元分裂，那么两两为一组，计算后加权后的Gini指数</p>
<h3 id="（重点）-过拟合问题和解决">（重点） 过拟合问题和解决</h3>
<p>过拟合：为了得到一致性假设而使<strong>假设变得过度复杂</strong>称为过拟合</p>
<p>过拟合是监督学习中普遍存在的问题</p>
<ul>
<li>原因：因为训练样本<strong>只是</strong>真实情况下的<strong>一个抽样集</strong></li>
<li>结果：<strong>泛化能力不强</strong></li>
</ul>
<h4 id="过拟合问题的解决策略">过拟合问题的解决策略</h4>
<ol>
<li>增加样本集</li>
<li>噪声去除</li>
<li>降低模型复杂度</li>
<li>模型选择正确：正则项等（例如选择VC堆）</li>
</ol>
<h4 id="（重点）在决策树中如何避免过拟合">（重点）在决策树中如何避免过拟合</h4>
<p>一颗归纳的树可能过分拟合数据训练数据造成的后果</p>
<ul>
<li>分支太多，某些反映训练数据中的异常，噪声/孤立点</li>
<li>未参与训练的样本的低精度预测</li>
</ul>
<p>具体做法</p>
<ul>
<li>限制决策树的层数来限制树的生长</li>
<li>设定每个节点必须包含的最少的记录数 节点个数小于这个最小记录数就停止分隔</li>
<li>树剪枝
<ul>
<li>先剪枝<strong>提前终止树构造</strong></li>
<li>后剪枝<strong>从完全生长的树中剪去树枝</strong>（但是后剪枝的计算量代价比先剪枝方法大很多！尤其是大样本集中）【在小样本中后剪枝要好】</li>
</ul>
</li>
</ul>
<h3 id="（重点）-KNN">（重点） KNN</h3>
<h4 id="基本思想">基本思想</h4>
<p>算法步骤：</p>
<ol>
<li>算距离：给定测试对象，计算它与训练集中的每个对象的距离</li>
<li>找邻居：圈定距离最近的k个训练对象，作为测试对象的近邻</li>
<li>做分类：根据这k个近邻归属主要的类别，来对测试对象分类</li>
</ol>
<h4 id="优缺点">优缺点</h4>
<p>优点：</p>
<ul>
<li>简单，易于实现，无需估计参数，无需训练</li>
<li>准确率一般较高</li>
<li>适合对稀有事件进行分类，特别适合于多分类问题</li>
</ul>
<p>缺点：</p>
<ul>
<li>懒惰算法，对测试样本分类时计算量大，内存开销大，评分慢</li>
<li>当类解释不平衡的时候，倾向于将类全部归于大类</li>
<li>可解释性差，无法给出决策树那样的规则。对噪声非常敏感</li>
</ul>
<h3 id="朴素贝叶斯">朴素贝叶斯</h3>
<p>关注分子：哪个更大<br>
找更大的y（y是类别）<br>
优点：概率输出，对文本分类效果较好</p>
<h3 id="（重点）SVM支持向量机">（重点）SVM支持向量机</h3>
<h4 id="（重点）SVM的优缺点">（重点）SVM的优缺点</h4>
<h4 id="什么是支持向量？">什么是支持向量？</h4>
<p>在<strong>分界点上的点</strong>称为支持向量</p>
<p>SVM的优点：</p>
<ol>
<li>可以处理小样本</li>
<li>泛化能力强</li>
</ol>
<h3 id="人工神经网络">人工神经网络</h3>
<p>人工神经网络（ANN，Artificial Neural Networks）是人类对大脑神经网络认识的基础上，人工构造的能够实现某种功能的神经网络。<br>
它是理论化的人脑神经系统的数学模型，是基于模仿大脑神经结构和功能而建立起来的一种信息处理系统。<br>
是一个多输入单输出的非线性阈值器件。</p>
<h3 id="集成学习">集成学习</h3>
<p>考的可能性不大，PPT里面没有<br>
集成学习：通过<strong>构建并结合多个学习器</strong>来完成学习任务，个体学习器要有一定的“准确性”，并且要有“多样性”，即学习器间有差异</p>
<blockquote>
<p>多样性是核心</p>
</blockquote>
<h3 id="分类评价指标">分类评价指标</h3>
<p><strong>准确度：Accuracy=$\frac{TP+TN}{ALL}$</strong><br>
精度<br>
A代表实际，PR代表预测，左上角和右下角是预测正确的<br>
<strong>准确度：Accuracy=$\frac{TP+TN}{ALL}$</strong><br>
<strong>误差率：1-Accuracy</strong><br>
<strong>错误率=$\frac{FP+FN}{ALL}$</strong><br>
<strong>精度：被分类预测为正确的占所有实际正确的比例$\frac{TP}{TP+FP}$</strong><br>
<strong>召回率：在所有实际正确的类别中被识别为正确的比率$\frac{TP}{TP+FN}$</strong></p>
<h3 id="练习题">练习题</h3>
<h2 id="第五章-聚类算法和噪声检测">第五章 聚类算法和噪声检测</h2>
<h3 id="复习提纲-5">复习提纲</h3>
<ol>
<li>什么是聚类？</li>
<li>聚类算法分类</li>
<li>KMEANS DBSCAN算法</li>
<li>什么是离群点？</li>
<li>离群点种类</li>
<li>LOF</li>
</ol>
<h3 id="什么是聚类">什么是聚类</h3>
<p>无监督学习的一种，就是将数据分为多个簇（Clusters），使得在同一簇内对象之间具有较高的相似度，而不同簇之间的对象差别较大.<br>
目的是寻找出数据中<strong>潜在的自然分组结构</strong>，<strong>让一个簇内的数据尽可能相似，不同簇内的数据尽可能不同</strong></p>
<h3 id="聚类算法分类">聚类算法分类</h3>
<p>一般而言，从<strong>不同角度出发</strong>可以将各种聚类算法分成不同的类型。如按照聚类的基本思想可主要分为：</p>
<ul>
<li>
<p>基于<strong>划分</strong>方法<br>
给定一个有n个对象的数据集，划分聚类技术将构造数据k个划分，每一个划分就代表一个簇<br>
对于给定的k，算法首先给出了一个初始的划分办法，以后“通过反复迭代的方法改变划分，使得每一次改进后的划分方案都较前一次更好”。经典的算法有：K-MEANS（K-均值），K-Medoids（K-中心点）等</p>
</li>
<li>
<p>基于<strong>层次</strong>方法<br>
层次聚类方法对给定的数据集进行层次的分解，直到满足某种条件为止<br>
<strong>凝聚的层次聚类</strong>是一种自底向上的策略，首先将每个对象作为一个簇，然后合并这些原子簇为越来越大的簇，知道某个终结条件被满足。AGENS算法<br>
<strong>分裂的层次聚类</strong></p>
</li>
<li>
<p>基于<strong>密度</strong>方法<br>
密度聚类方法的指导思想是，只要一个区域中的点的密度大于某个阈值，就可把它加到与之相近的聚类中去。<br>
这类算法<strong>能克服基于距离的算法只能发现“类圆形”的聚类的缺点</strong>，可以发现任意形状，<strong>且对噪声数据不敏感</strong></p>
</li>
<li>
<p>基于<strong>网格</strong>方法<br>
将对象空间量化为有限数目的单元，形成一个网格结构，所有的聚类都在这个网格结构上进行。</p>
</li>
</ul>
<h3 id="（重点）KMEANS">（重点）KMEANS</h3>
<p>KMEANS</p>
<ul>
<li>选取K个点作为初始的类中心点，这些点一般都是从数据集中随机抽取的</li>
<li>将每个点分配到最近的类中心点，这样就形成了K个类，然后重新计算每个类的中心点；（一般用欧几里得距离公式算最近，用每个维度的平均值重新计算每个类的中心点）</li>
<li>重复第二步，直到类不发生变化，或者你也可以设置最大迭代次数，这样即使类中心点发生变化，但是只要达到最大迭代次数就会结束</li>
</ul>
<h3 id="KMEANS优缺点">KMEANS优缺点</h3>
<p>优点：速度快，相对可伸缩和高效率<br>
缺点：对K值敏感，对初值敏感，<strong>不适合非球形的簇</strong>，对孤立点和噪声敏感</p>
<h3 id="（重点）DBSCAN">（重点）DBSCAN</h3>
<p>缺点：</p>
<ul>
<li>对参数EPS和Minspt非常敏感，但是这两个参数的选取主要依靠主观判断</li>
<li>数据库比较大的话，会有比较大的IO开销</li>
</ul>
<h3 id="什么是离群点">什么是离群点</h3>
<p>“离群点是一个数据对象，它显著不同于其他数据对象，好像它是被不同的机制产生的一样。”</p>
<blockquote>
<p>异常数据具有<strong>特殊意义和很高的使用价值</strong>，异常数据虽然有时候或作为离群点被排斥掉，但是却也有可能给我们新的视角，比如</p>
</blockquote>
<ul>
<li>在欺诈检测中，异常数据可能意味着欺诈行为的发生</li>
<li>在入侵检验中，异常数据可能意味着入侵行为的发生</li>
</ul>
<h3 id="离群点种类">离群点种类</h3>
<ul>
<li>全局离群点 和别的一点点关系都没有</li>
<li>局部离群点，对全局来说不是离群点，但是对于某个簇来说是离群点</li>
<li>集体离群点 某一个群体和其他不同</li>
</ul>
<h3 id="LOF离群（异常-孤立）点检测">LOF离群（异常/孤立）点检测</h3>
<ul>
<li>基于统计学的孤立点检测</li>
<li>基于距离的孤立点检测</li>
<li>基于偏离的孤立点检测</li>
<li>基于密度判断：<br>
对象P的局部可达密度(Local Reachable Distance)<br>
对象P的局部可达密度为对象P与它的MinPts-邻域的平均可达距离的倒数<br>
对象P的局部异常因子（Local Outlier Factor）<br>
Lrd是局部密度，所以孤立点的密度小，分子大，分母小，所以最终结果大<br>
对象P的局部异常因子表示P的异常程度，局部异常因子愈大，就认为它可能更异常，反之可能性越小</li>
</ul>
<h2 id="第六章-大数据分析">第六章 大数据分析</h2>
<h3 id="复习提纲-6">复习提纲</h3>
<p>哈希技术</p>
<ul>
<li>Mini Hash 最小哈希-签名矩阵的计算</li>
<li>LSH局部敏感哈希</li>
<li>其中 签名矩阵的计算 与局部敏感哈希近似<br>
数据流挖掘</li>
<li>数据流挑战</li>
<li>概念漂移（PCC（x）改变）检测方法</li>
<li>分类（VFDT$\to$Hoe）</li>
<li>聚类：线上+线下
<ul>
<li>线上：数据抽象：微簇</li>
<li>线下：KMEANS DBSCAN</li>
</ul>
</li>
</ul>
<h3 id="哈希技术">哈希技术</h3>
<h4 id="（重点）-Min哈希（最小哈希）">（重点） Min哈希（最小哈希）</h4>
<p>步骤</p>
<ol>
<li>计算签名矩阵<br>
<strong>（重点） 会算签名矩阵</strong></li>
<li>通过签名矩阵寻找相似的签名</li>
<li>检测签名相似的是否真的相似（可选）</li>
</ol>
<p>主要思想：<br>
把每一列转换成一个更小的签名矩阵C，让C足够小能够放到内存里面，让C1和C2能表征原始数据的相似性<br>
相似性用雅阁比距离来表征：$\frac{a}{a+b+c}$ a为两者都是1，b和c表示一个0和一个1<br>
最小哈希定义<br>
首次出现1的行号</p>
<h4 id="LSH（局部敏感哈希）">LSH（局部敏感哈希）</h4>
<p><strong>原因</strong><br>
想要比较两个文档，一一校对是非常苦难的，提出LSH<br>
<strong>哈希的思想</strong><br>
不一一匹配，把数据放到桶里，<strong>每个桶里的东西都非常相似</strong><br>
把列向量b划分为b块，对每一块进行映射，如果是相似的，那么至少有一块会映射到一个桶子里<br>
将签名矩阵划分为几块，对每一块进行映射，候选对是至少散列到一个桶的对<br>
概率随比例变化<br>
将每一列划分为b个bands，然后每个bands分别放到桶里<br>
如果相似度很大（超过0.5），至少有一个band全部放到一个桶里，就可以放到一起</p>
<h3 id="数据流挖掘">数据流挖掘</h3>
<p><strong>（重点）如何检测概念漂移</strong><br>
数据流：<strong>持续的依次到达的对象，无穷长，有概念漂移</strong><br>
挑战：<strong>单程处理，内存限制，低时间复杂度，概念漂移</strong><br>
<strong>概念漂移</strong><br>
在预测分析和机器学习中，概念漂移意味着模型试图预测目标的统计特征随时间以不可预见的方式改变<br>
条件概率发生变化<br>
如下图，中间是真正的概念漂移，右边是虚假的，如果P（x）变化整体不会变<br>
<strong>如何检测数据漂移</strong><br>
<strong>使用分布</strong><br>
用于检测突变的概念漂移<br>
检测相同时间间隔（窗口）检测P（C|X）,如果检测到变化就说明发生了<br>
问题：1.窗口大小不好确定；2.学习漂移慢；3.虚假的概念漂移<br>
ADWIM：处理当前数据，发生显著性变化就用新的替代老的<br>
<strong>错误率</strong><br>
缺点：1.对噪声敏感 2.对缓慢变化的数据难以处理 3.取决于学习模型的健壮性<br>
<strong>分类</strong><br>
传统静态不适用，每一次输入一个数据后快速进行分类<br>
方法：快速决策树（VFDT）<br>
动态地构造决策树，利用小部分数据构造<br>
算法：假如新来的数据满足关系，那么就划分一次 如果错误变多了，那么可以认为是发生了概念漂移，使用新的节点<br>
<strong>聚类</strong><br>
数据流抽象，分为在线和离线<br>
线上把数据用合适地数据结构处理，线下用传统方式去进行聚类<br>
微簇：用几个点表示几个相近的点<br>
动态变化，线上（重要），如何去线上整出这些微簇<br>
<strong>簇特征（重要）</strong><br>
CF=（N，LS，SS）N是点的个数，LS是横坐标之和，SS是横坐标平方和<br>
<strong>为什么要做处理</strong></p>
<ol>
<li>可以计算这些点的中心和半径</li>
<li>可以支持动态增量式计算</li>
<li>因为数据连续不断的进入，只需要加新增的数据就可以（可加性，可减性）</li>
</ol>
<h3 id="（重点）-Hadoop-spark的基本概念！">（重点） Hadoop/spark的基本概念！</h3>
<p><strong>Hadoop</strong>：Hadoop是一个软件框架，用于跨大型计算机群对大型数据集进行分布式处理TB PB级别<br>
<strong>Spark</strong>：一个统一的完整的引擎<br>
<strong>Hadoop设计准则</strong><br>
需要处理大数据<br>
需要跨数千个节点并行计算，大量廉价机器并行计算<br>
分而治之<br>
1.自动并行化 2.容错和自动恢复 3.给用户提供接口<br>
<strong>Hadoop生态</strong><br>
MapReduce（计算）和HDFS（存储） ZOOKeeper用来协调<br>
<strong>HDFS怎么存储</strong><br>
分而治之，分为很多块<br>
Namenode和Datanode<br>
用Namenode去存哪一块放到哪个机器里面，存储数据原信息<br>
Datenode存储实际数据，文件被存在各个节点里，拥有时钟机制，每个几秒发送一次汇报工作，如果过了很久还没能发送，那么已经默认你已经挂掉，重新创建节点存储被挂掉节点存储的数据<br>
可以存储大数据<br>
<strong>MapReduce VS Spark</strong><br>
MaoReduce适用于一次操作，对多次操作不适用，共享机制落后，花费大量时间IO<br>
Spark是用于推广reduce去支持同一引擎的新应用，拥有RDD支持内存计算，提供多种API<br>
<strong>RDD弹性分布式数据集</strong><br>
只读，便于内存计算<br>
操作方式：</p>
<ol>
<li>Transformation<br>
他从现有的数据集创建一个新数据集，所有操作都是懒惰的</li>
<li>Action<br>
它在对数据集运行计算后向驱动程序返回一个值</li>
</ol>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="mailto:2039222749@qq.com">Komorebi</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="https://wenxilzy.github.io/2022/05/27/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98%E4%B8%8E%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E5%A4%8D%E4%B9%A0/">https://wenxilzy.github.io/2022/05/27/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98%E4%B8%8E%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E5%A4%8D%E4%B9%A0/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="https://wenxilzy.github.io" target="_blank">Komorebi</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98%E4%B8%8E%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/">数据挖掘与大数据分析</a><a class="post-meta__tags" href="/tags/%E5%A4%8D%E4%B9%A0/">复习</a></div><div class="post_share"><div class="social-share" data-image="https://cdn.acwing.com/media/article/image/2022/05/16/99310_ddc885a5d4-00117.png" data-sites="wechat,weibo,qq"></div><link rel="stylesheet" href="https://fastly.jsdelivr.net/npm/social-share.js/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://fastly.jsdelivr.net/npm/social-share.js/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2022/06/04/%E6%AD%A6%E9%92%9F%E7%A5%A5%E8%80%81%E5%B8%88%E6%AF%8F%E6%97%A5%E4%B8%80%E9%A2%98%E7%AC%AC211-223%E9%A2%98/"><img class="prev-cover" src="https://cdn.acwing.com/media/article/image/2022/05/16/99310_c43571b1d4-00028.png" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">武忠祥老师每日一题第211-223题</div></div></a></div><div class="next-post pull-right"><a href="/2022/05/27/%E8%BD%AF%E4%BB%B6%E6%8A%80%E6%9C%AF%E5%9F%BA%E7%A1%80%E5%A4%8D%E4%B9%A0/"><img class="next-cover" src="https://cdn.acwing.com/media/article/image/2022/05/16/99310_dfda541bd4-2.png" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">软件技术基础复习</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><div><a href="/2022/05/23/%E8%AE%A1%E7%AE%97%E6%99%BA%E8%83%BD%E5%A4%8D%E4%B9%A0/" title="计算智能复习"><img class="cover" src="https://cdn.acwing.com/media/article/image/2022/05/16/99310_dcbdb406d4-1.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-05-23</div><div class="title">计算智能复习</div></div></a></div><div><a href="/2022/05/20/%E8%AE%A1%E9%87%8F%E7%BB%8F%E6%B5%8E%E5%AD%A6%E5%A4%8D%E4%B9%A0/" title="计量经济学复习"><img class="cover" src="https://cdn.acwing.com/media/article/image/2022/05/16/99310_e95e2ec8d4-6.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-05-20</div><div class="title">计量经济学复习</div></div></a></div><div><a href="/2022/05/27/%E8%BD%AF%E4%BB%B6%E6%8A%80%E6%9C%AF%E5%9F%BA%E7%A1%80%E5%A4%8D%E4%B9%A0/" title="软件技术基础复习"><img class="cover" src="https://cdn.acwing.com/media/article/image/2022/05/16/99310_dfda541bd4-2.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-05-27</div><div class="title">软件技术基础复习</div></div></a></div></div></div><hr/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> 评论</span></div><div id="comment-switch"><span class="first-comment">Valine</span><span class="switch-btn"></span><span class="second-comment">Disqus</span></div></div><div class="comment-wrap"><div><div class="vcomment" id="vcomment"></div></div><div><div id="disqus_thread"></div></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="https://cdn.acwing.com/media/article/image/2022/04/28/99310_dfcf84d4c6-touxiang.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">Komorebi</div><div class="author-info__description">自信人生二百年,会当水击三千里</div></div><div class="card-info-data is-center"><div class="card-info-data-item"><a href="/archives/"><div class="headline">文章</div><div class="length-num">55</div></a></div><div class="card-info-data-item"><a href="/tags/"><div class="headline">标签</div><div class="length-num">18</div></a></div><div class="card-info-data-item"><a href="/categories/"><div class="headline">分类</div><div class="length-num">5</div></a></div></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/xxxxxx"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/wenxilzy" target="_blank" title="Github"><i class="fab fa-github"></i></a><a class="social-icon" href="mailto:2039222749@qq.com" target="_blank" title="Email"><i class="fas fa-envelope"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">个人QQ：2039222749 欢迎大家交流</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%A2%98%E5%9E%8B"><span class="toc-number">1.</span> <span class="toc-text">题型</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%AC%AC%E4%B8%80%E7%AB%A0-%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98%E4%B8%8E%E5%A4%A7%E6%95%B0%E6%8D%AE%E7%AE%80%E4%BB%8B"><span class="toc-number">2.</span> <span class="toc-text">第一章 数据挖掘与大数据简介</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%A4%8D%E4%B9%A0%E6%8F%90%E7%BA%B2"><span class="toc-number">2.1.</span> <span class="toc-text">复习提纲</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5"><span class="toc-number">2.2.</span> <span class="toc-text">基本概念</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BB%80%E4%B9%88%E6%98%AF%E5%A4%A7%E6%95%B0%E6%8D%AE"><span class="toc-number">2.2.1.</span> <span class="toc-text">什么是大数据</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BB%80%E4%B9%88%E6%98%AF%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98"><span class="toc-number">2.2.2.</span> <span class="toc-text">什么是数据挖掘</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%A4%A7%E6%95%B0%E6%8D%AE%E7%9A%844V%E7%89%B9%E5%BE%81"><span class="toc-number">2.2.3.</span> <span class="toc-text">大数据的4V特征</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98%E4%B8%BB%E8%A6%81%E4%BB%BB%E5%8A%A1"><span class="toc-number">2.3.</span> <span class="toc-text">数据挖掘主要任务</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%EF%BC%88%E9%87%8D%E7%82%B9%EF%BC%89KDD%E8%BF%87%E7%A8%8B%EF%BC%88%E7%9F%A5%E8%AF%86%E5%8F%91%E7%8E%B0%E8%BF%87%E7%A8%8B%EF%BC%89"><span class="toc-number">2.4.</span> <span class="toc-text">（重点）KDD过程（知识发现过程）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98%E6%8C%91%E6%88%98"><span class="toc-number">2.5.</span> <span class="toc-text">数据挖掘挑战</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98%E4%B8%8E%E5%A4%9A%E4%B8%AA%E5%AD%A6%E7%A7%91%E8%9E%8D%E5%90%88"><span class="toc-number">2.6.</span> <span class="toc-text">数据挖掘与多个学科融合</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%AC%AC%E4%BA%8C%E7%AB%A0-%E8%AE%A4%E8%AF%86%E6%95%B0%E6%8D%AE%E5%92%8C%E6%95%B0%E6%8D%AE%E9%A2%84%E5%A4%84%E7%90%86"><span class="toc-number">3.</span> <span class="toc-text">第二章 认识数据和数据预处理</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%A4%8D%E4%B9%A0%E6%8F%90%E7%BA%B2-2"><span class="toc-number">3.1.</span> <span class="toc-text">复习提纲</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%B1%9E%E6%80%A7%E7%B1%BB%E5%9E%8B"><span class="toc-number">3.2.</span> <span class="toc-text">属性类型</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B"><span class="toc-number">3.3.</span> <span class="toc-text">数据类型</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%EF%BC%88%E9%87%8D%E7%82%B9%EF%BC%89%E3%80%90%E9%80%89%E5%A1%AB%E9%A2%98%E3%80%91%E6%95%B0%E6%8D%AE%E7%9A%84%E6%8F%8F%E8%BF%B0%E6%80%A7%E7%BB%9F%E8%AE%A1"><span class="toc-number">3.4.</span> <span class="toc-text">（重点）【选填题】数据的描述性统计</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%B8%AD%E5%BF%83%E8%B6%8B%E5%8A%BF%E5%BA%A6%E9%87%8F"><span class="toc-number">3.4.1.</span> <span class="toc-text">中心趋势度量</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E7%9A%84%E6%95%A3%E5%B8%83"><span class="toc-number">3.4.2.</span> <span class="toc-text">数据的散布</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%EF%BC%88%E9%87%8D%E7%82%B9%EF%BC%89%E3%80%90%E4%B8%8A%E6%9C%BA%E5%AE%9E%E4%B9%A0%E3%80%91-%E6%95%B0%E6%8D%AE%E7%9A%84%E7%9B%B8%E4%BC%BC%E5%BA%A6%E5%BA%A6%E9%87%8F"><span class="toc-number">3.5.</span> <span class="toc-text">（重点）【上机实习】 数据的相似度度量</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%A0%87%E7%A7%B0%E5%B1%9E%E6%80%A7%E6%95%B0%E6%8D%AE"><span class="toc-number">3.5.1.</span> <span class="toc-text">标称属性数据</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BA%8C%E5%85%83%E5%8F%98%E9%87%8F%E5%B1%9E%E6%80%A7%E6%95%B0%E6%8D%AE"><span class="toc-number">3.5.2.</span> <span class="toc-text">二元变量属性数据</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%BA%8F%E6%95%B0%E5%9E%8B%E5%8F%98%E9%87%8F%E6%95%B0%E6%8D%AE"><span class="toc-number">3.5.3.</span> <span class="toc-text">序数型变量数据</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%95%B0%E5%80%BC%E5%B1%9E%E6%80%A7%E6%95%B0%E6%8D%AE"><span class="toc-number">3.5.4.</span> <span class="toc-text">数值属性数据</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E6%A0%87%E5%87%86%E5%8C%96"><span class="toc-number">3.5.5.</span> <span class="toc-text">数据标准化</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%B7%B7%E5%90%88%E5%9E%8B%E6%95%B0%E6%8D%AE"><span class="toc-number">3.5.6.</span> <span class="toc-text">混合型数据</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%9B%B8%E4%BC%BC%E6%80%A7%E5%BA%A6%E9%87%8F"><span class="toc-number">3.5.7.</span> <span class="toc-text">相似性度量</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%EF%BC%88%E9%87%8D%E7%82%B9%EF%BC%89%E6%95%B0%E6%8D%AE%E9%A2%84%E5%A4%84%E7%90%86"><span class="toc-number">3.6.</span> <span class="toc-text">（重点）数据预处理</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%B8%BA%E4%BB%80%E4%B9%88%E8%A6%81%E6%8C%96%E6%8E%98%EF%BC%9F"><span class="toc-number">3.6.1.</span> <span class="toc-text">为什么要挖掘？</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E9%A2%84%E5%A4%84%E7%90%86%E7%9A%84%E4%B8%BB%E8%A6%81%E4%BB%BB%E5%8A%A1"><span class="toc-number">3.6.2.</span> <span class="toc-text">数据预处理的主要任务</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%EF%BC%88%E9%87%8D%E7%82%B9%EF%BC%89-%E6%95%B0%E6%8D%AE%E6%B8%85%E7%90%86-%EF%BC%88%E6%95%B0%E6%8D%AE%E7%9A%84%E5%A1%AB%E5%85%85%E6%96%B9%E5%BC%8F%E9%87%8D%E7%82%B9%EF%BC%89"><span class="toc-number">3.6.2.1.</span> <span class="toc-text">（重点） 数据清理 （数据的填充方式重点）</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E9%9B%86%E6%88%90"><span class="toc-number">3.6.2.2.</span> <span class="toc-text">数据集成</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E8%A7%84%E7%BA%A6"><span class="toc-number">3.6.2.3.</span> <span class="toc-text">数据规约</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E5%8F%98%E5%8C%96"><span class="toc-number">3.6.2.4.</span> <span class="toc-text">数据变化</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E7%A6%BB%E6%95%A3%E5%8C%96"><span class="toc-number">3.6.2.5.</span> <span class="toc-text">数据离散化</span></a></li></ol></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%AC%AC%E4%B8%89%E7%AB%A0-%E5%85%B3%E8%81%94%E8%A7%84%E5%88%99%E6%8C%96%E6%8E%98"><span class="toc-number">4.</span> <span class="toc-text">第三章 关联规则挖掘</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%A4%8D%E4%B9%A0%E6%8F%90%E7%BA%B2-3"><span class="toc-number">4.1.</span> <span class="toc-text">复习提纲</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%AE%9A%E4%B9%89%E4%BB%A5%E5%8F%8A%E4%B8%80%E4%BA%9B%E6%A6%82%E5%BF%B5"><span class="toc-number">4.2.</span> <span class="toc-text">定义以及一些概念</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Apriori%E7%AE%97%E6%B3%95"><span class="toc-number">4.3.</span> <span class="toc-text">Apriori算法</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#FP-growth%E7%AE%97%E6%B3%95"><span class="toc-number">4.4.</span> <span class="toc-text">FP-growth算法</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%94%AF%E6%8C%81%E5%BA%A6%EF%BC%8C%E7%BD%AE%E4%BF%A1%E5%BA%A6%E5%8F%8A%E5%85%B4%E8%B6%A3%E5%9B%A0%E5%AD%90"><span class="toc-number">4.5.</span> <span class="toc-text">支持度，置信度及兴趣因子</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%AC%AC%E5%9B%9B%E7%AB%A0-%E5%88%86%E7%B1%BB-%E5%9B%9E%E5%BD%92"><span class="toc-number">5.</span> <span class="toc-text">第四章 分类&#x2F;回归</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%A4%8D%E4%B9%A0%E6%8F%90%E7%BA%B2-4"><span class="toc-number">5.1.</span> <span class="toc-text">复习提纲</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5-2"><span class="toc-number">5.2.</span> <span class="toc-text">基本概念</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0-VS-%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0"><span class="toc-number">5.2.1.</span> <span class="toc-text">监督学习 VS 无监督学习</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%EF%BC%88%E9%87%8D%E8%A6%81%EF%BC%89-%E6%A8%A1%E5%9E%8B%E5%88%86%E7%B1%BB"><span class="toc-number">5.2.2.</span> <span class="toc-text">（重要） 模型分类</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B"><span class="toc-number">5.2.2.1.</span> <span class="toc-text">生成模型</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%88%A4%E5%88%AB%E6%A8%A1%E5%9E%8B"><span class="toc-number">5.2.2.2.</span> <span class="toc-text">判别模型</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E4%BA%8C%E8%80%85%E7%9A%84%E5%8C%BA%E5%88%AB"><span class="toc-number">5.2.2.3.</span> <span class="toc-text">二者的区别</span></a></li></ol></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%86%B3%E7%AD%96%E6%A0%91%EF%BC%88DT%EF%BC%89"><span class="toc-number">5.3.</span> <span class="toc-text">决策树（DT）</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%EF%BC%88%E9%87%8D%E7%82%B9%EF%BC%89-%E5%86%B3%E7%AD%96%E6%A0%91%E7%9A%84%E4%BC%98%E7%BC%BA%E7%82%B9"><span class="toc-number">5.3.1.</span> <span class="toc-text">（重点） 决策树的优缺点</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%EF%BC%88%E9%87%8D%E7%82%B9%EF%BC%89-%E6%9E%84%E5%BB%BA%E5%86%B3%E7%AD%96%E6%A0%91%E7%9A%84%E6%96%B9%E6%B3%95"><span class="toc-number">5.3.2.</span> <span class="toc-text">（重点） 构建决策树的方法</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%EF%BC%88%E9%87%8D%E7%82%B9%EF%BC%89-%E5%B1%9E%E6%80%A7%E9%80%89%E6%8B%A9%E5%9F%BA%E6%9C%AC%E5%87%86%E5%88%99"><span class="toc-number">5.3.3.</span> <span class="toc-text">（重点） 属性选择基本准则</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%EF%BC%88%E9%87%8D%E7%82%B9%EF%BC%89-%E4%BF%A1%E6%81%AF%E5%A2%9E%E7%9B%8A%EF%BC%88ID3%EF%BC%89"><span class="toc-number">5.3.3.1.</span> <span class="toc-text">（重点） 信息增益（ID3）</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%EF%BC%88%E9%87%8D%E7%82%B9%EF%BC%89-%E4%BF%A1%E6%81%AF%E5%A2%9E%E7%9B%8A%E7%8E%87%EF%BC%88C4-5%EF%BC%89"><span class="toc-number">5.3.3.2.</span> <span class="toc-text">（重点） 信息增益率（C4.5）</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#Gini%E6%8C%87%E6%95%B0%EF%BC%88CART%EF%BC%89"><span class="toc-number">5.3.3.3.</span> <span class="toc-text">Gini指数（CART）</span></a></li></ol></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%EF%BC%88%E9%87%8D%E7%82%B9%EF%BC%89-%E8%BF%87%E6%8B%9F%E5%90%88%E9%97%AE%E9%A2%98%E5%92%8C%E8%A7%A3%E5%86%B3"><span class="toc-number">5.4.</span> <span class="toc-text">（重点） 过拟合问题和解决</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%BF%87%E6%8B%9F%E5%90%88%E9%97%AE%E9%A2%98%E7%9A%84%E8%A7%A3%E5%86%B3%E7%AD%96%E7%95%A5"><span class="toc-number">5.4.1.</span> <span class="toc-text">过拟合问题的解决策略</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%EF%BC%88%E9%87%8D%E7%82%B9%EF%BC%89%E5%9C%A8%E5%86%B3%E7%AD%96%E6%A0%91%E4%B8%AD%E5%A6%82%E4%BD%95%E9%81%BF%E5%85%8D%E8%BF%87%E6%8B%9F%E5%90%88"><span class="toc-number">5.4.2.</span> <span class="toc-text">（重点）在决策树中如何避免过拟合</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%EF%BC%88%E9%87%8D%E7%82%B9%EF%BC%89-KNN"><span class="toc-number">5.5.</span> <span class="toc-text">（重点） KNN</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%9F%BA%E6%9C%AC%E6%80%9D%E6%83%B3"><span class="toc-number">5.5.1.</span> <span class="toc-text">基本思想</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BC%98%E7%BC%BA%E7%82%B9"><span class="toc-number">5.5.2.</span> <span class="toc-text">优缺点</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF"><span class="toc-number">5.6.</span> <span class="toc-text">朴素贝叶斯</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%EF%BC%88%E9%87%8D%E7%82%B9%EF%BC%89SVM%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA"><span class="toc-number">5.7.</span> <span class="toc-text">（重点）SVM支持向量机</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%EF%BC%88%E9%87%8D%E7%82%B9%EF%BC%89SVM%E7%9A%84%E4%BC%98%E7%BC%BA%E7%82%B9"><span class="toc-number">5.7.1.</span> <span class="toc-text">（重点）SVM的优缺点</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BB%80%E4%B9%88%E6%98%AF%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%EF%BC%9F"><span class="toc-number">5.7.2.</span> <span class="toc-text">什么是支持向量？</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BA%BA%E5%B7%A5%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C"><span class="toc-number">5.8.</span> <span class="toc-text">人工神经网络</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0"><span class="toc-number">5.9.</span> <span class="toc-text">集成学习</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%88%86%E7%B1%BB%E8%AF%84%E4%BB%B7%E6%8C%87%E6%A0%87"><span class="toc-number">5.10.</span> <span class="toc-text">分类评价指标</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%BB%83%E4%B9%A0%E9%A2%98"><span class="toc-number">5.11.</span> <span class="toc-text">练习题</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%AC%AC%E4%BA%94%E7%AB%A0-%E8%81%9A%E7%B1%BB%E7%AE%97%E6%B3%95%E5%92%8C%E5%99%AA%E5%A3%B0%E6%A3%80%E6%B5%8B"><span class="toc-number">6.</span> <span class="toc-text">第五章 聚类算法和噪声检测</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%A4%8D%E4%B9%A0%E6%8F%90%E7%BA%B2-5"><span class="toc-number">6.1.</span> <span class="toc-text">复习提纲</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BB%80%E4%B9%88%E6%98%AF%E8%81%9A%E7%B1%BB"><span class="toc-number">6.2.</span> <span class="toc-text">什么是聚类</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%81%9A%E7%B1%BB%E7%AE%97%E6%B3%95%E5%88%86%E7%B1%BB"><span class="toc-number">6.3.</span> <span class="toc-text">聚类算法分类</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%EF%BC%88%E9%87%8D%E7%82%B9%EF%BC%89KMEANS"><span class="toc-number">6.4.</span> <span class="toc-text">（重点）KMEANS</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#KMEANS%E4%BC%98%E7%BC%BA%E7%82%B9"><span class="toc-number">6.5.</span> <span class="toc-text">KMEANS优缺点</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%EF%BC%88%E9%87%8D%E7%82%B9%EF%BC%89DBSCAN"><span class="toc-number">6.6.</span> <span class="toc-text">（重点）DBSCAN</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BB%80%E4%B9%88%E6%98%AF%E7%A6%BB%E7%BE%A4%E7%82%B9"><span class="toc-number">6.7.</span> <span class="toc-text">什么是离群点</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%A6%BB%E7%BE%A4%E7%82%B9%E7%A7%8D%E7%B1%BB"><span class="toc-number">6.8.</span> <span class="toc-text">离群点种类</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#LOF%E7%A6%BB%E7%BE%A4%EF%BC%88%E5%BC%82%E5%B8%B8-%E5%AD%A4%E7%AB%8B%EF%BC%89%E7%82%B9%E6%A3%80%E6%B5%8B"><span class="toc-number">6.9.</span> <span class="toc-text">LOF离群（异常&#x2F;孤立）点检测</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%AC%AC%E5%85%AD%E7%AB%A0-%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90"><span class="toc-number">7.</span> <span class="toc-text">第六章 大数据分析</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%A4%8D%E4%B9%A0%E6%8F%90%E7%BA%B2-6"><span class="toc-number">7.1.</span> <span class="toc-text">复习提纲</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%93%88%E5%B8%8C%E6%8A%80%E6%9C%AF"><span class="toc-number">7.2.</span> <span class="toc-text">哈希技术</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%EF%BC%88%E9%87%8D%E7%82%B9%EF%BC%89-Min%E5%93%88%E5%B8%8C%EF%BC%88%E6%9C%80%E5%B0%8F%E5%93%88%E5%B8%8C%EF%BC%89"><span class="toc-number">7.2.1.</span> <span class="toc-text">（重点） Min哈希（最小哈希）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#LSH%EF%BC%88%E5%B1%80%E9%83%A8%E6%95%8F%E6%84%9F%E5%93%88%E5%B8%8C%EF%BC%89"><span class="toc-number">7.2.2.</span> <span class="toc-text">LSH（局部敏感哈希）</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E6%B5%81%E6%8C%96%E6%8E%98"><span class="toc-number">7.3.</span> <span class="toc-text">数据流挖掘</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%EF%BC%88%E9%87%8D%E7%82%B9%EF%BC%89-Hadoop-spark%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5%EF%BC%81"><span class="toc-number">7.4.</span> <span class="toc-text">（重点） Hadoop&#x2F;spark的基本概念！</span></a></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2022/06/08/%E6%AD%A6%E5%BF%A0%E7%A5%A5%E8%80%81%E5%B8%88%E6%AF%8F%E6%97%A5%E4%B8%80%E9%A2%98%E7%AC%AC368-380%E9%A2%98/" title="武忠祥老师每日一题第368-380题"><img src="https://cdn.acwing.com/media/article/image/2022/05/16/99310_e38e1bf3d4-3.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="武忠祥老师每日一题第368-380题"/></a><div class="content"><a class="title" href="/2022/06/08/%E6%AD%A6%E5%BF%A0%E7%A5%A5%E8%80%81%E5%B8%88%E6%AF%8F%E6%97%A5%E4%B8%80%E9%A2%98%E7%AC%AC368-380%E9%A2%98/" title="武忠祥老师每日一题第368-380题">武忠祥老师每日一题第368-380题</a><time datetime="2022-06-08T09:09:23.000Z" title="发表于 2022-06-08 17:09:23">2022-06-08</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2022/06/08/%E6%97%A5%E5%B8%B8%E7%94%9F%E6%B4%BB%E4%B8%AD%E5%90%B8%E5%8F%96%E7%9A%84%E6%95%99%E8%AE%AD/" title="日常生活中吸取的教训"><img src="https://cdn.acwing.com/media/article/image/2022/05/16/99310_e1ef396dd4-00189.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="日常生活中吸取的教训"/></a><div class="content"><a class="title" href="/2022/06/08/%E6%97%A5%E5%B8%B8%E7%94%9F%E6%B4%BB%E4%B8%AD%E5%90%B8%E5%8F%96%E7%9A%84%E6%95%99%E8%AE%AD/" title="日常生活中吸取的教训">日常生活中吸取的教训</a><time datetime="2022-06-08T02:44:24.000Z" title="发表于 2022-06-08 10:44:24">2022-06-08</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2022/06/07/%E4%B8%BB%E7%A0%81%E5%92%8C%E5%80%99%E9%80%89%E7%A0%81%E7%9A%84%E5%8C%BA%E5%88%AB/" title="主码和候选码的区别"><img src="https://cdn.acwing.com/media/article/image/2022/05/16/99310_e1ef396dd4-00189.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="主码和候选码的区别"/></a><div class="content"><a class="title" href="/2022/06/07/%E4%B8%BB%E7%A0%81%E5%92%8C%E5%80%99%E9%80%89%E7%A0%81%E7%9A%84%E5%8C%BA%E5%88%AB/" title="主码和候选码的区别">主码和候选码的区别</a><time datetime="2022-06-07T02:58:11.000Z" title="发表于 2022-06-07 10:58:11">2022-06-07</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2022/06/06/%E6%9A%91%E6%9C%9F%E5%89%8D%E9%9B%86%E8%AE%AD%E6%90%9C%E7%B4%A2%E4%B8%8E%E5%AD%97%E7%AC%A6%E4%B8%B2%E4%B8%93%E9%A2%98/" title="暑期前集训搜索与字符串专题"><img src="https://cdn.acwing.com/media/article/image/2022/05/16/99310_ed8cfc7ed4-7.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="暑期前集训搜索与字符串专题"/></a><div class="content"><a class="title" href="/2022/06/06/%E6%9A%91%E6%9C%9F%E5%89%8D%E9%9B%86%E8%AE%AD%E6%90%9C%E7%B4%A2%E4%B8%8E%E5%AD%97%E7%AC%A6%E4%B8%B2%E4%B8%93%E9%A2%98/" title="暑期前集训搜索与字符串专题">暑期前集训搜索与字符串专题</a><time datetime="2022-06-06T08:49:50.000Z" title="发表于 2022-06-06 16:49:50">2022-06-06</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2022/06/05/%E6%AD%A6%E5%BF%A0%E7%A5%A5%E8%80%81%E5%B8%88%E6%AF%8F%E6%97%A5%E4%B8%80%E9%A2%98%E7%AC%AC356-367%E9%A2%98/" title="武忠祥老师每日一题第356-367题"><img src="https://cdn.acwing.com/media/article/image/2022/05/16/99310_e38e1bf3d4-3.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="武忠祥老师每日一题第356-367题"/></a><div class="content"><a class="title" href="/2022/06/05/%E6%AD%A6%E5%BF%A0%E7%A5%A5%E8%80%81%E5%B8%88%E6%AF%8F%E6%97%A5%E4%B8%80%E9%A2%98%E7%AC%AC356-367%E9%A2%98/" title="武忠祥老师每日一题第356-367题">武忠祥老师每日一题第356-367题</a><time datetime="2022-06-05T05:49:20.000Z" title="发表于 2022-06-05 13:49:20">2022-06-05</time></div></div></div></div></div></div></main><footer id="footer" style="background-image: url('https://cdn.acwing.com/media/article/image/2022/04/29/99310_a4e287c0c7-footer.png')"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2022 By Komorebi</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="chat_btn" type="button" title="聊天"><i class="fas fa-sms"></i></button><a id="to_comment" href="#post-comment" title="直达评论"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></div><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">本地搜索</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="is-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span>  数据库加载中</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div><hr/><div id="local-search-results"></div></div></div><div id="search-mask"></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://fastly.jsdelivr.net/npm/medium-zoom/dist/medium-zoom.min.js"></script><script>function panguFn () {
  if (typeof pangu === 'object') pangu.autoSpacingPage()
  else {
    getScript('https://fastly.jsdelivr.net/npm/pangu/dist/browser/pangu.min.js')
      .then(() => {
        pangu.autoSpacingPage()
      })
  }
}

function panguInit () {
  if (false){
    GLOBAL_CONFIG_SITE.isPost && panguFn()
  } else {
    panguFn()
  }
}

document.addEventListener('DOMContentLoaded', panguInit)</script><script src="/js/search/local-search.js"></script><script>var preloader = {
  endLoading: () => {
    document.body.style.overflow = 'auto';
    document.getElementById('loading-box').classList.add("loaded")
  },
  initLoading: () => {
    document.body.style.overflow = '';
    document.getElementById('loading-box').classList.remove("loaded")

  }
}
window.addEventListener('load',preloader.endLoading())</script><div class="js-pjax"><script>if (!window.MathJax) {
  window.MathJax = {
    tex: {
      inlineMath: [ ['$','$'], ["\\(","\\)"]],
      tags: 'ams'
    },
    chtml: {
      scale: 1.2
    },
    options: {
      renderActions: {
        findScript: [10, doc => {
          for (const node of document.querySelectorAll('script[type^="math/tex"]')) {
            const display = !!node.type.match(/; *mode=display/)
            const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display)
            const text = document.createTextNode('')
            node.parentNode.replaceChild(text, node)
            math.start = {node: text, delim: '', n: 0}
            math.end = {node: text, delim: '', n: 0}
            doc.math.push(math)
          }
        }, ''],
        insertScript: [200, () => {
          document.querySelectorAll('mjx-container:not\([display]\)').forEach(node => {
            const target = node.parentNode
            if (target.nodeName.toLowerCase() === 'li') {
              target.parentNode.classList.add('has-jax')
            } else {
              target.classList.add('has-jax')
            }
          });
        }, '', false]
      }
    }
  }
  
  const script = document.createElement('script')
  script.src = 'https://fastly.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js'
  script.id = 'MathJax-script'
  script.async = true
  document.head.appendChild(script)
} else {
  MathJax.startup.document.state(0)
  MathJax.texReset()
  MathJax.typeset()
}</script><script>function loadValine () {
  function initValine () {
    const valine = new Valine(Object.assign({
      el: '#vcomment',
      appId: 'wX2XPR5wOL6aJ8jBbOdg7trP-gzGzoHsz',
      appKey: 'Y51G9WhyCNKKAk8bcqX5459G',
      avatar: 'https://cdn.acwing.com/media/article/image/2022/04/29/99310_7f50d0aec7-avatar2.png',
      serverURLs: '',
      emojiMaps: "",
      path: window.location.pathname,
      visitor: false
    }, null))
  }

  if (typeof Valine === 'function') initValine() 
  else getScript('https://fastly.jsdelivr.net/npm/valine/dist/Valine.min.js').then(initValine)
}

if ('Valine' === 'Valine' || !true) {
  if (true) btf.loadComment(document.getElementById('vcomment'),loadValine)
  else setTimeout(loadValine, 0)
} else {
  function loadOtherComment () {
    loadValine()
  }
}</script><script>function loadDisqus () {
  var disqus_config = function () {
    this.page.url = 'https://wenxilzy.github.io/2022/05/27/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98%E4%B8%8E%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E5%A4%8D%E4%B9%A0/'
    this.page.identifier = '2022/05/27/数据挖掘与大数据分析复习/'
    this.page.title = '数据挖掘与大数据分析复习'
  };

  window.disqusReset = () => {
    DISQUS.reset({
      reload: true,
      config: disqus_config
    })
  }

  if (window.DISQUS) disqusReset()
  else {
    (function() { 
      var d = document, s = d.createElement('script');
      s.src = 'https://.disqus.com/embed.js';
      s.setAttribute('data-timestamp', +new Date());
      (d.head || d.body).appendChild(s);
    })();
  }
}

if ('Valine' === 'Disqus' || !true) {
  if (true) btf.loadComment(document.getElementById('disqus_thread'), loadDisqus)
  else loadDisqus()
} else {
  function loadOtherComment () {
    loadDisqus()
  }
}
</script></div><script src="https://fastly.jsdelivr.net/npm/butterfly-extsrc@1/dist/activate-power-mode.min.js"></script><script>POWERMODE.colorful = true;
POWERMODE.shake = false;
POWERMODE.mobile = false;
document.body.addEventListener('input', POWERMODE);
</script><script id="click-heart" src="https://fastly.jsdelivr.net/npm/butterfly-extsrc@1/dist/click-heart.min.js" async="async" mobile="false"></script><script>(function(i,s,o,g,r,a,m){i["DaoVoiceObject"]=r;i[r]=i[r]||function(){(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;a.charset="utf-8";m.parentNode.insertBefore(a,m)})(window,document,"script",('https:' == document.location.protocol ? 'https:' : 'http:') + "//widget.daovoice.io/widget/172c8bea.js","daovoice")
</script><script>var isChatBtn = true
daovoice('init', {
  app_id: '172c8bea',},{
  launcher: { 
     disableLauncherIcon: isChatBtn // 悬浮 ICON 是否显示
  },
});
daovoice('update');

if (isChatBtn) {
  var chatBtnFn = () => {
    var chatBtn = document.getElementById("chat_btn")
    chatBtn.addEventListener("click", function(){
      daovoice('show')
    });
  }
  chatBtnFn()
} else {
  if (false) {
    function chatBtnHide () {
      daovoice('update', {},{
        launcher: { 
        disableLauncherIcon: true // 悬浮 ICON 是否显示
        },
      });
    }
    function chatBtnShow () {
      daovoice('update', {},{
        launcher: { 
        disableLauncherIcon: false // 悬浮 ICON 是否显示
        },
      });
    }
  }
}</script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>